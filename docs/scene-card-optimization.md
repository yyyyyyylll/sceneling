# 场景卡片两阶段加载优化设计文档

## 一、问题背景

用户上传照片后，需要等待 **40-60 秒**的空白加载页面才能看到学习内容。长时间的无反馈等待导致用户焦虑、流失率上升。

---

## 二、问题分析

### 任务依赖关系

场景分析功能包含两类任务：

| 任务类型 | 具体内容 | 输入依赖 |
|---------|---------|---------|
| 图像理解 | 场景识别、词汇提取、描述生成 | 必须分析图片 |
| 文本生成 | 口语例句生成 | 仅需场景描述文本 |

### 问题本质

原方案将两类任务打包为单次请求，存在以下问题：

1. **串行阻塞**：文本生成任务必须等待图像理解完成，但实际上它只依赖图像理解的输出结果，而非图片本身
2. **资源浪费**：使用多模态模型处理纯文本任务，成本高、速度慢
3. **体验断层**：用户要么看不到任何内容，要么一次性看到全部

### 核心洞察

> 口语例句生成不依赖图片，只依赖"场景是什么"这一信息。一旦获得场景描述，即可启动第二阶段生成。

---

## 三、解决方案

### 流程对比

**优化前**：串行执行，全量返回

```
用户上传图片
    ↓
多模态模型分析（40-60秒）
    ├── 识别场景
    ├── 提取词汇
    ├── 生成描述
    └── 生成口语例句  ← 其实不需要看图
    ↓
一次性返回全部结果
    ↓
页面渲染
```

**优化后**：分阶段执行，流式返回

```
用户上传图片
    ↓
┌─────────────────────────────────┐
│ 第一阶段：多模态模型（10-20秒）  │
│   ├── 识别场景 ✓                │
│   ├── 提取词汇 ✓                │
│   └── 生成描述 ✓                │
└─────────────────────────────────┘
    ↓
立即返回基础结果 → 用户看到内容
    ↓
同时启动第二阶段
    ↓
┌─────────────────────────────────┐
│ 第二阶段：纯文本模型（5-10秒）   │
│   └── 生成口语例句              │
│       （输入：场景描述，无需图片）│
└─────────────────────────────────┘
    ↓
增量返回例句 → 页面自动更新
```

### 技术实现

采用 **Server-Sent Events (SSE)** 流式推送，事件序列如下：

```
{ type: "basic", data: {场景、词汇、描述} }  → 触发首屏渲染
{ type: "expressions", data: {口语例句} }    → 增量更新
{ type: "done" }                             → 完成
```

### 模型选型

| 阶段 | 模型类型 | 选型依据 |
|-----|---------|---------|
| 第一阶段 | 多模态模型 (qwen-vl-max) | 需要图像理解能力 |
| 第二阶段 | 纯文本模型 (qwen-turbo) | 仅需文本输入，响应更快、成本更低 |

---

## 四、实施效果

### 性能指标

| 指标 | 优化前 | 优化后 | 改善 |
|-----|-------|-------|-----|
| 首屏时间 | 40-60s | 10-20s | ↓ 60-70% |
| 完整加载 | 40-60s | 15-30s | ↓ 50% |

### 体验改善

- 用户在 10-20 秒内即可看到场景卡片并开始学习，等待时间大幅度下降

### 成本收益

- 第二阶段使用轻量模型，API 调用成本降低
- 任务并行化后，总耗时缩短

### 隐性指标保障
- 经人工评估，纯文本模型 (qwen-turbo)相较多模态模型 (qwen-vl-max)，在模型表现和用户感知层面没有显著差异

---

## 五、方法论提炼

> **渐进式交付：先给用户可用的内容，再逐步完善细节。**

核心思路：

1. **拆解任务依赖**：识别哪些任务可以解耦、并行或延后
2. **按价值排序**：优先交付用户最先关注的内容
3. **匹配资源与需求**：为不同任务选择合适的执行方式